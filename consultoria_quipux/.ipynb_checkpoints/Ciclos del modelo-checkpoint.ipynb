{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciclos del modelo\n",
    "\n",
    "El modelo de semejanza recorre un orden determinado de instrucciones que parametrizamos desde el script de criterios de ejecución\n",
    "\n",
    "Los ciclos le dan un orden al proceso, una estructura homogenea a cada tabla de datos y flexibilidad de métodos para generar los resultados.\n",
    "\n",
    "* Breve resumen de los ciclos:\n",
    "    + inicio_modelo\n",
    "    + ciclo por corridas \n",
    "    + ciclo por métodos\n",
    "\n",
    "El proceso comienza en el script `inicio_modelo`, donde tenemos parametrizadas las bases de datos `origen` y `destino`. llamamos la función `calcular` del script `coordinador_criterios` parametrizada como `calcular(origen, destino)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import coordinador_criterios as homologar\n",
    "\n",
    "import lectura_datos.datos_ministerio as datos_min\n",
    "import lectura_datos.vehiculos as vehiculos\n",
    "\n",
    "import utils.set_up as set_up\n",
    "\n",
    "# Iniciamos los archivos de entrada y salida\n",
    "set_up.inicio()\n",
    "\n",
    "# Cargamos base de datos\n",
    "\n",
    "tablas_ministerio = datos_min.min_imp()\n",
    "vehiculos_sap, registros_unicos = vehiculos.cargar_sap(tipo = True)\n",
    "\n",
    "# # Cálculamos criterios\n",
    "\n",
    "homologar.calcular(registros_unicos, tablas_ministerio) # (origen, destino)\n",
    "\n",
    "# Finalizamos para organizar los archivos de entrada y salida en orden periodico\n",
    "set_up.final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso continua con el ciclo de `corrida`, este ciclo se parametriza en el script `criterios_ejecucion` y es representado por cada elemento de la lista `col_index`.  \n",
    "en este punto tenemos las siguientes instrucciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular( origen, destino):\n",
    "    \n",
    "    # Iniciamos el dataframe 'sin_coincidencia' objetivo del proceso\n",
    "    sin_coincidencia = origen.copy()\n",
    "    \n",
    "    # Iniciamos el ciclo por corrida, dado los n elementos de la lista col_index\n",
    "    for i, iteracion in enumerate(ce.col_index):\n",
    "        \n",
    "        # Inicializamos el objeto 'indice'\n",
    "        indice = datos.Indice(iteracion, ce.criterios)\n",
    "        \n",
    "        # Mostramos corrida actual\n",
    "        ut.save_log(f'## Corrida: {indice.corrida}')\n",
    "\n",
    "        if i == 0:\n",
    "            \n",
    "            sin_coincidencia = sin_coincidencia[indice.origen_id + indice.estrictas + indice.flexibles + indice.conservar_origen]\n",
    "\n",
    "            exacta = pd.DataFrame()\n",
    "            homologaciones = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "\n",
    "            sin_coincidencia.rename(index = str, columns = {'LINEA': 'LINEA2'}, inplace = True)\n",
    "            \n",
    "        # Iniciamos el ciclo por métodos\n",
    "        for criterio, valor in indice.criterios.itertuples(index=False):  \n",
    "            {\n",
    "                \n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso continua con el ciclo por métodos, donde se lleva el seguimiento de los dataframe `exacta`, `homologaciones` y `sin coincidencia`, que contienen el seguimiento de todos los registros de `origen` durante el proceso.  \n",
    "Este proceso es fundamental para coordinas los filtros y las funciones aplicadas a los registros de `origen`, por tal razón se debe garatizar que se conserva la integridad de esta base de datos cada vez que modificamos o agregamos nuevos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos el ciclo por métodos\n",
    "for criterio, valor in indice.criterios.itertuples(index=False):  \n",
    "\n",
    "            #Calculamos desagregar\n",
    "                    \n",
    "            if criterio == 'desagregar' and valor:\n",
    "                ut.save_log('### Desagregando')\n",
    "                sin_coincidencia = desagregar.desagregar(indice, \n",
    "                        sin_coincidencia)\n",
    "\n",
    "            # Calculamos exactas\n",
    "            \n",
    "            if criterio == 'exactas' and valor:\n",
    "                ut.save_log('### Coincidencias exactas')                \n",
    "                if len(exacta) <= 0:\n",
    "                    k = 1\n",
    "                    exacta, sin_coincidencia = exactas.exactas(indice, \n",
    "                            sin_coincidencia, destino, k)\n",
    "                else: # if len(exacta) > 0:\n",
    "                    k += 1\n",
    "                    temp = exacta\n",
    "                    exacta, sin_coincidencia = exactas.exactas(indice, \n",
    "                            sin_coincidencia, destino, k)\n",
    "                    exacta = pd.concat([temp, exacta])\n",
    "\n",
    "                # Imprimir exactas\n",
    "\n",
    "                name = 'exactas_corrida_' + str(i+1) + '.csv'\n",
    "                exacta.to_csv(os.path.abspath(os.path.join(path, name)), sep = ';', \n",
    "                        index = False)\n",
    "                ut.save_log(f'Archivos generado: {name}')\n",
    "                \n",
    "            # Calculamos semajanza\n",
    "            \n",
    "            if criterio == 'semejanza' and valor:\n",
    "                ut.save_log('### Calculando semejanza') \n",
    "                if len(homologaciones)>0:\n",
    "                    temp = homologaciones.copy()\n",
    "                    homologaciones, sin_coincidencia = semejanza.semejanza(\n",
    "                            indice, sin_coincidencia, destino)\n",
    "                    \n",
    "                    homologaciones = pd.concat([temp, homologaciones]) \n",
    "                else:\n",
    "                    homologaciones, sin_coincidencia = semejanza.semejanza(\n",
    "                            indice, sin_coincidencia, destino)  \n",
    "                \n",
    "            # Calculamos contenida\n",
    "\n",
    "            if criterio == 'palabras_contenidas' and valor:\n",
    "                ut.save_log('### Calculando palabras contenidas') \n",
    "                \n",
    "                if len(homologaciones)>0:\n",
    "                    temp = homologaciones.copy()\n",
    "                    homologaciones, sin_coincidencia = (\n",
    "                            contenida.palabra_contenida_sin_orden(indice, \n",
    "                                    sin_coincidencia, destino)\n",
    "                            )\n",
    "                    \n",
    "                    homologaciones = pd.concat([temp, homologaciones], sort=False) \n",
    "                else:\n",
    "                    homologaciones, sin_coincidencia = (\n",
    "                            contenida.palabra_contenida_sin_orden(\n",
    "                                    indice, sin_coincidencia, destino)\n",
    "                            )\n",
    "                \n",
    "            # Calculamos desempate\n",
    "\n",
    "            if criterio == 'desempate' and valor:\n",
    "                for columna in indice.desempate_cols:\n",
    "                    \n",
    "                    # Cada columna acumula en homologaciones los resultados filtrados en homologaciones\n",
    "                    # Es importante no perder ningún registro en origen_id durante este proceso\n",
    "                    homologaciones = desempate.desempate(indice, homologaciones, columna)\n",
    "                    duplicados = df[df[indice.origen_id].duplicated(keep = False)]\n",
    "                    if duplicados.shape[0] > 0:\n",
    "                        ut.save_log(f'Existen duplicados despues correr desempate por {columna}')\n",
    "#                        import pdb; pdb.set_trace()\n",
    "            \n",
    "            # Coincidencias cruzadas\n",
    "            \n",
    "            if criterio == 'cruzar' and valor:\n",
    "                \n",
    "                cruzar.destino_origen(indice, destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de finalizar el ciclo por métodos, el modelo genera los archivos de salida de las tablas `homologaciones` y `sin coincidencia`, además genera el informe o 'bitácora' del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "ut.save_log('## Generación de archivos')\n",
    "\n",
    "# Imprimir homologaciones\n",
    "\n",
    "name = 'homologaciones_corrida_' + str(i+1) + '.csv'\n",
    "homologaciones.to_csv(os.path.abspath(os.path.join(path, name)), \n",
    "        sep = ';', index = False)\n",
    "ut.save_log(f'Archivos generado: {name}')\n",
    "ut.docs_save(name)\n",
    "\n",
    "# Imprimir sin coincidencia\n",
    "\n",
    "name = 'sin_coincidencia_corrida_' + str(i+1) + '.csv'\n",
    "sin_coincidencia.to_csv(os.path.abspath(os.path.join(path, name)), \n",
    "        sep = ';', index = False)\n",
    "ut.save_log(f'Archivos generado: {name}')\n",
    "ut.docs_save(name)\n",
    "\n",
    "# Generación informes\n",
    "\n",
    "gi.generar_informe()\n",
    "\n",
    "return homologaciones, sin_coincidencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación el procedimiento completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import objetos.datos as datos\n",
    "import criterios_ejecucion as ce\n",
    "import metodos.desagregar as desagregar\n",
    "import metodos.exactas as exactas\n",
    "import metodos.semejanza as semejanza\n",
    "import metodos.contenida as contenida\n",
    "import metodos.desempate as desempate\n",
    "import metodos.cruzar as cruzar\n",
    "\n",
    "import utils.utils as ut\n",
    "import utils.generar_informe as gi\n",
    "import metadata.directory as metadir\n",
    "\n",
    "path = metadir.Path.CARPETA_RESULTADOS\n",
    "\n",
    "def calcular( origen, destino):\n",
    "\n",
    "    sin_coincidencia = origen.copy()\n",
    "    \n",
    "    for i, iteracion in enumerate(ce.col_index):\n",
    "        \n",
    "        indice = datos.Indice(iteracion, ce.criterios)\n",
    "        \n",
    "        # Mostramos corrida actual\n",
    "        ut.save_log(f'## Corrida: {indice.corrida}')\n",
    "\n",
    "        # Criterios de la   corrida\n",
    "\n",
    "        # print('Criterios: exactas, semejanza, palabras_contenidas, desempate, cruzar, desagregar')\n",
    "        # in_criterios = input('¿Cuáles métodos desea hacer?:')\n",
    "\n",
    "        if i == 0:\n",
    "            \n",
    "            sin_coincidencia = sin_coincidencia[indice.origen_id + indice.estrictas + indice.flexibles + indice.conservar_origen]\n",
    "\n",
    "            exacta = pd.DataFrame()\n",
    "            homologaciones = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "\n",
    "            sin_coincidencia.rename(index = str, columns = {'LINEA': 'LINEA2'}, inplace = True)\n",
    "\n",
    "        for criterio, valor in indice.criterios.itertuples(index=False):  \n",
    "\n",
    "            #Calculamos desagregar\n",
    "                    \n",
    "            if criterio == 'desagregar' and valor:\n",
    "                ut.save_log('### Desagregando')\n",
    "                sin_coincidencia = desagregar.desagregar(indice, \n",
    "                        sin_coincidencia)\n",
    "\n",
    "            # Calculamos exactas\n",
    "            \n",
    "            if criterio == 'exactas' and valor:\n",
    "                ut.save_log('### Coincidencias exactas')                \n",
    "                if len(exacta) <= 0:\n",
    "                    k = 1\n",
    "                    exacta, sin_coincidencia = exactas.exactas(indice, \n",
    "                            sin_coincidencia, destino, k)\n",
    "                else: # if len(exacta) > 0:\n",
    "                    k += 1\n",
    "                    temp = exacta\n",
    "                    exacta, sin_coincidencia = exactas.exactas(indice, \n",
    "                            sin_coincidencia, destino, k)\n",
    "                    exacta = pd.concat([temp, exacta])\n",
    "\n",
    "                # Imprimir exactas\n",
    "\n",
    "                name = 'exactas_corrida_' + str(i+1) + '.csv'\n",
    "                exacta.to_csv(os.path.abspath(os.path.join(path, name)), sep = ';', \n",
    "                        index = False)\n",
    "                ut.save_log(f'Archivos generado: {name}')\n",
    "                \n",
    "            # Calculamos semajanza\n",
    "            \n",
    "            if criterio == 'semejanza' and valor:\n",
    "                ut.save_log('### Calculando semejanza') \n",
    "                if len(homologaciones)>0:\n",
    "                    temp = homologaciones.copy()\n",
    "                    homologaciones, sin_coincidencia = semejanza.semejanza(\n",
    "                            indice, sin_coincidencia, destino)\n",
    "                    \n",
    "                    homologaciones = pd.concat([temp, homologaciones]) \n",
    "                else:\n",
    "                    homologaciones, sin_coincidencia = semejanza.semejanza(\n",
    "                            indice, sin_coincidencia, destino)  \n",
    "                \n",
    "            # Calculamos contenida\n",
    "\n",
    "            if criterio == 'palabras_contenidas' and valor:\n",
    "                ut.save_log('### Calculando palabras contenidas') \n",
    "                \n",
    "                if len(homologaciones)>0:\n",
    "                    temp = homologaciones.copy()\n",
    "                    homologaciones, sin_coincidencia = (\n",
    "                            contenida.palabra_contenida_sin_orden(indice, \n",
    "                                    sin_coincidencia, destino)\n",
    "                            )\n",
    "                    \n",
    "                    homologaciones = pd.concat([temp, homologaciones], sort=False) \n",
    "                else:\n",
    "                    homologaciones, sin_coincidencia = (\n",
    "                            contenida.palabra_contenida_sin_orden(\n",
    "                                    indice, sin_coincidencia, destino)\n",
    "                            )\n",
    "                \n",
    "            # Calculamos desempate\n",
    "\n",
    "            if criterio == 'desempate' and valor:\n",
    "                for columna in indice.desempate_cols:\n",
    "                    \n",
    "                    # Cada columna acumula en homologaciones los resultados filtrados en homologaciones\n",
    "                    # Es importante no perder ningún registro en origen_id durante este proceso\n",
    "                    homologaciones = desempate.desempate(indice, homologaciones, columna)\n",
    "                    duplicados = df[df[indice.origen_id].duplicated(keep = False)]\n",
    "                    if duplicados.shape[0] > 0:\n",
    "                        ut.save_log(f'Existen duplicados despues correr desempate por {columna}')\n",
    "#                        import pdb; pdb.set_trace()\n",
    "            \n",
    "            # Coincidencias cruzadas\n",
    "            \n",
    "            if criterio == 'cruzar' and valor:\n",
    "                \n",
    "                cruzar.destino_origen(indice, destino)\n",
    "\n",
    "    ut.save_log('## Generación de archivos')\n",
    "\n",
    "    # Imprimir homologaciones\n",
    "\n",
    "    name = 'homologaciones_corrida_' + str(i+1) + '.csv'\n",
    "    homologaciones.to_csv(os.path.abspath(os.path.join(path, name)), \n",
    "            sep = ';', index = False)\n",
    "    ut.save_log(f'Archivos generado: {name}')\n",
    "    ut.docs_save(name)\n",
    "\n",
    "    # Imprimir sin coincidencia\n",
    "\n",
    "    name = 'sin_coincidencia_corrida_' + str(i+1) + '.csv'\n",
    "    sin_coincidencia.to_csv(os.path.abspath(os.path.join(path, name)), \n",
    "            sep = ';', index = False)\n",
    "    ut.save_log(f'Archivos generado: {name}')\n",
    "    ut.docs_save(name)\n",
    "    \n",
    "    # Generación informes\n",
    "\n",
    "    gi.generar_informe()\n",
    "\n",
    "    return homologaciones, sin_coincidencia\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
